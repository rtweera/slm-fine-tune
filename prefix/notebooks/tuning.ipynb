{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a343064-c5ae-45ea-8ea9-a7af82b483c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ab414f5-40a7-482e-9cfc-b85508b93ddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "510f901c-c529-4b59-897a-5eb9186f5122",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(os.getenv('hf_token'))\n",
    "assert(os.getenv('WANDB_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d645e005-3a1a-46f5-865f-4fd0894a330b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: peft in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (0.15.2)\n",
      "Collecting wandb\n",
      "  Downloading wandb-0.19.10-py3-none-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from peft) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from peft) (25.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from peft) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from peft) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from peft) (2.7.0)\n",
      "Requirement already satisfied: transformers in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from peft) (4.51.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from peft) (4.67.1)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from peft) (1.6.0)\n",
      "Requirement already satisfied: safetensors in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from peft) (0.5.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from peft) (0.30.2)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from wandb) (8.1.8)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from wandb) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from wandb) (4.3.7)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<7,>=3.19.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from wandb) (5.29.4)\n",
      "Requirement already satisfied: pydantic<3 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from wandb) (2.11.3)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from wandb) (2.32.3)\n",
      "Collecting sentry-sdk>=2.0.0 (from wandb)\n",
      "  Downloading sentry_sdk-2.27.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Downloading setproctitle-1.3.6-cp312-cp312-win_amd64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from wandb) (80.0.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from wandb) (4.13.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from click!=8.0.0,>=7.1->wandb) (0.4.6)\n",
      "Requirement already satisfied: six>=1.4.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
      "Requirement already satisfied: filelock in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from huggingface_hub>=0.25.0->peft) (2025.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from pydantic<3->wandb) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from pydantic<3->wandb) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from pydantic<3->wandb) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from requests<3,>=2.0.0->wandb) (2025.4.26)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from torch>=1.13.0->peft) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from torch>=1.13.0->peft) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from torch>=1.13.0->peft) (3.1.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from transformers->peft) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from transformers->peft) (0.21.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from sympy>=1.13.3->torch>=1.13.0->peft) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from jinja2->torch>=1.13.0->peft) (3.0.2)\n",
      "Downloading wandb-0.19.10-py3-none-win_amd64.whl (20.7 MB)\n",
      "   ---------------------------------------- 0.0/20.7 MB ? eta -:--:--\n",
      "   - -------------------------------------- 0.5/20.7 MB 3.3 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 2.1/20.7 MB 6.2 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 4.2/20.7 MB 7.4 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 5.8/20.7 MB 7.5 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 8.1/20.7 MB 8.2 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 10.5/20.7 MB 8.7 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 12.8/20.7 MB 9.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 15.5/20.7 MB 9.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 18.1/20.7 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  20.7/20.7 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  20.7/20.7 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  20.7/20.7 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  20.7/20.7 MB 10.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 20.7/20.7 MB 7.4 MB/s eta 0:00:00\n",
      "Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Downloading sentry_sdk-2.27.0-py2.py3-none-any.whl (340 kB)\n",
      "Downloading setproctitle-1.3.6-cp312-cp312-win_amd64.whl (12 kB)\n",
      "Installing collected packages: setproctitle, sentry-sdk, docker-pycreds, wandb\n",
      "Successfully installed docker-pycreds-0.4.0 sentry-sdk-2.27.0 setproctitle-1.3.6 wandb-0.19.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install peft wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fe9f6a4-1435-484c-8a99-080c9746b57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, DataCollatorForLanguageModeling\n",
    "from peft import PrefixTuningConfig, get_peft_model\n",
    "import wandb\n",
    "from huggingface_hub import login\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c9f8375-f538-49a3-8b3c-db8f7c836919",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d48c9fc9-1d56-4811-9c43-73b1186c8334",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "wandb: WARNING Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "wandb: No netrc file found, creating one.\n",
      "wandb: Appending key for api.wandb.ai to your netrc file: C:\\Users\\Ravindu\\_netrc\n",
      "wandb: Currently logged in as: rtweera (rtw-rtweera) to https://api.wandb.ai. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.10"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\prefix\\notebooks\\wandb\\run-20250505_201827-nd0svh80</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/rtw-rtweera/prefix-tuning-qwen-25-question-generation/runs/nd0svh80' target=\"_blank\">qwen25-0.5b-prefix-tuning</a></strong> to <a href='https://wandb.ai/rtw-rtweera/prefix-tuning-qwen-25-question-generation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/rtw-rtweera/prefix-tuning-qwen-25-question-generation' target=\"_blank\">https://wandb.ai/rtw-rtweera/prefix-tuning-qwen-25-question-generation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/rtw-rtweera/prefix-tuning-qwen-25-question-generation/runs/nd0svh80' target=\"_blank\">https://wandb.ai/rtw-rtweera/prefix-tuning-qwen-25-question-generation/runs/nd0svh80</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/rtw-rtweera/prefix-tuning-qwen-25-question-generation/runs/nd0svh80?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x2728aec9760>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login(key=os.getenv('WANDB_API_KEY'))\n",
    "wandb.init(project=\"prefix-tuning-qwen-25-question-generation\", name='qwen25-0.5b-prefix-tuning')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04580276-5c8e-493e-b308-db66fbbd856b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "login(token=os.getenv('hf_token'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56027f61-695c-46c1-aa90-e7819bcb3560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db8f66cda2124b82925ae378215cbfff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/7.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\venv-slm-fine-tune\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Ravindu\\.cache\\huggingface\\hub\\datasets--squad. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e2973b949d453eb336124e6a283830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05bee5a13b4b49909f83d2bfbbc819eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e666b96a704130ba864d56fca36c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00853aca7819460f8de065df46ef1185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('squad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b27ca873-e83a-4732-88ea-f87e3dfe2588",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3b09b792-e644-4a2a-af97-7950cd6fad13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "428c4cdc-99a7-4216-8df4-95f38115e638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1a33e438-0725-443a-bb4b-e3879c521ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7f55749f-a71a-4a55-8a83-2b2038b80bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answers': {'answer_start': [74],\n",
      "             'text': ['Michigan Wolverines football team']},\n",
      " 'context': 'The Notre Dame football team has a long history, first beginning '\n",
      "            'when the Michigan Wolverines football team brought football to '\n",
      "            'Notre Dame in 1887 and played against a group of students. In the '\n",
      "            'long history since then, 13 Fighting Irish teams have won '\n",
      "            'consensus national championships (although the university only '\n",
      "            'claims 11), along with another nine teams being named national '\n",
      "            'champion by at least one source. Additionally, the program has '\n",
      "            'the most members in the College Football Hall of Fame, is tied '\n",
      "            'with Ohio State University with the most Heisman Trophies won, '\n",
      "            'and have the highest winning percentage in NCAA history. With the '\n",
      "            'long history, Notre Dame has accumulated many rivals, and its '\n",
      "            'annual game against USC for the Jeweled Shillelagh has been named '\n",
      "            'by some as one of the most important in college football and is '\n",
      "            'often called the greatest intersectional rivalry in college '\n",
      "            'football in the country.',\n",
      " 'id': '5733c4494776f419006611da',\n",
      " 'question': \"Which team did Notre Dame's football team find inspiration from?\",\n",
      " 'title': 'University_of_Notre_Dame'}\n"
     ]
    }
   ],
   "source": [
    "pprint(dataset['train'][234])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20871c3d-2154-428f-a33d-e9b2c547f5b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc0e2d0d91f403d80db5ffc7df7c7b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\venv-slm-fine-tune\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Ravindu\\.cache\\huggingface\\hub\\models--Qwen--Qwen2.5-0.5B. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205aeeddc30d4932b4f8462a977337df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "054e94f0893b48ae88668ace246d5cbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4717e059427b42f4b8c53b9e59b9a671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'Qwen/Qwen2.5-0.5B'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f50737fc-218c-4e65-87d4-ee8b4cd22d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "01aa6c80-9b91-4792-8b6c-270f0622eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example_batch):\n",
    "    prompt = 'Generate a question from this given context:'\n",
    "    inputs = [f'{prompt} {context} -> {question}' for context, question in zip(example_batch['context'], example_batch['question'])]\n",
    "    tokenized = tokenizer(\n",
    "        inputs,\n",
    "        max_length=256,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    tokenized['labels'] = tokenized['input_ids'].clone()\n",
    "    return tokenized\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e6485318-e8f3-4bf6-96d1-f031761f17b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79f501433b474708b50248c38e6e3d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1c5ed4dbbd74b5a8722b90031e83c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n",
      "<class 'datasets.formatting.formatting.LazyBatch'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.map(lambda x: print(type(x)), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f91c7e8a-219c-4568-80bf-9191534292b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3979c6407a1c42b5802b2829ecadf32d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "014b6c3c5ff645908a76f21d16d8d998",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized = dataset.map(preprocess, batched=True, remove_columns = dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6babe391-c42a-4c33-843f-5f1b1e35642d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "670db571-673c-4f68-a52c-c48ddd5ed9dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [31115,\n",
       "  264,\n",
       "  3405,\n",
       "  504,\n",
       "  419,\n",
       "  2661,\n",
       "  2266,\n",
       "  25,\n",
       "  7297,\n",
       "  20288,\n",
       "  220,\n",
       "  20,\n",
       "  15,\n",
       "  572,\n",
       "  458,\n",
       "  3693,\n",
       "  8964,\n",
       "  1809,\n",
       "  311,\n",
       "  8253,\n",
       "  279,\n",
       "  18319,\n",
       "  315,\n",
       "  279,\n",
       "  5055,\n",
       "  20761,\n",
       "  8953,\n",
       "  320,\n",
       "  87101,\n",
       "  8,\n",
       "  369,\n",
       "  279,\n",
       "  220,\n",
       "  17,\n",
       "  15,\n",
       "  16,\n",
       "  20,\n",
       "  3200,\n",
       "  13,\n",
       "  576,\n",
       "  3693,\n",
       "  20761,\n",
       "  14872,\n",
       "  320,\n",
       "  32,\n",
       "  6754,\n",
       "  8,\n",
       "  18319,\n",
       "  22117,\n",
       "  41594,\n",
       "  23283,\n",
       "  279,\n",
       "  5055,\n",
       "  20761,\n",
       "  14872,\n",
       "  320,\n",
       "  45,\n",
       "  6754,\n",
       "  8,\n",
       "  18319,\n",
       "  12740,\n",
       "  44167,\n",
       "  220,\n",
       "  17,\n",
       "  19,\n",
       "  4142,\n",
       "  16,\n",
       "  15,\n",
       "  311,\n",
       "  7232,\n",
       "  862,\n",
       "  4843,\n",
       "  7297,\n",
       "  20288,\n",
       "  2265,\n",
       "  13,\n",
       "  576,\n",
       "  1809,\n",
       "  572,\n",
       "  6342,\n",
       "  389,\n",
       "  7400,\n",
       "  220,\n",
       "  22,\n",
       "  11,\n",
       "  220,\n",
       "  17,\n",
       "  15,\n",
       "  16,\n",
       "  21,\n",
       "  11,\n",
       "  518,\n",
       "  55041,\n",
       "  594,\n",
       "  22636,\n",
       "  304,\n",
       "  279,\n",
       "  5836,\n",
       "  12879,\n",
       "  9154,\n",
       "  12030,\n",
       "  518,\n",
       "  15993,\n",
       "  50557,\n",
       "  11,\n",
       "  7043,\n",
       "  13,\n",
       "  1634,\n",
       "  419,\n",
       "  572,\n",
       "  279,\n",
       "  220,\n",
       "  20,\n",
       "  15,\n",
       "  339,\n",
       "  7297,\n",
       "  20288,\n",
       "  11,\n",
       "  279,\n",
       "  10734,\n",
       "  45628,\n",
       "  279,\n",
       "  330,\n",
       "  97235,\n",
       "  21582,\n",
       "  1,\n",
       "  448,\n",
       "  5257,\n",
       "  6623,\n",
       "  56589,\n",
       "  27172,\n",
       "  11,\n",
       "  438,\n",
       "  1632,\n",
       "  438,\n",
       "  27092,\n",
       "  9298,\n",
       "  2459,\n",
       "  279,\n",
       "  13815,\n",
       "  315,\n",
       "  34948,\n",
       "  1817,\n",
       "  7297,\n",
       "  20288,\n",
       "  1809,\n",
       "  448,\n",
       "  12751,\n",
       "  7857,\n",
       "  1127,\n",
       "  320,\n",
       "  7995,\n",
       "  892,\n",
       "  279,\n",
       "  1809,\n",
       "  1035,\n",
       "  614,\n",
       "  1012,\n",
       "  3881,\n",
       "  438,\n",
       "  330,\n",
       "  19284,\n",
       "  20288,\n",
       "  444,\n",
       "  3975,\n",
       "  773,\n",
       "  429,\n",
       "  279,\n",
       "  12426,\n",
       "  1410,\n",
       "  72988,\n",
       "  4565,\n",
       "  279,\n",
       "  34117,\n",
       "  7857,\n",
       "  1127,\n",
       "  220,\n",
       "  20,\n",
       "  15,\n",
       "  13,\n",
       "  1464,\n",
       "  15920,\n",
       "  12588,\n",
       "  2083,\n",
       "  15251,\n",
       "  279,\n",
       "  63536,\n",
       "  518,\n",
       "  7297,\n",
       "  20288,\n",
       "  220,\n",
       "  20,\n",
       "  15,\n",
       "  30,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'labels': [31115,\n",
       "  264,\n",
       "  3405,\n",
       "  504,\n",
       "  419,\n",
       "  2661,\n",
       "  2266,\n",
       "  25,\n",
       "  7297,\n",
       "  20288,\n",
       "  220,\n",
       "  20,\n",
       "  15,\n",
       "  572,\n",
       "  458,\n",
       "  3693,\n",
       "  8964,\n",
       "  1809,\n",
       "  311,\n",
       "  8253,\n",
       "  279,\n",
       "  18319,\n",
       "  315,\n",
       "  279,\n",
       "  5055,\n",
       "  20761,\n",
       "  8953,\n",
       "  320,\n",
       "  87101,\n",
       "  8,\n",
       "  369,\n",
       "  279,\n",
       "  220,\n",
       "  17,\n",
       "  15,\n",
       "  16,\n",
       "  20,\n",
       "  3200,\n",
       "  13,\n",
       "  576,\n",
       "  3693,\n",
       "  20761,\n",
       "  14872,\n",
       "  320,\n",
       "  32,\n",
       "  6754,\n",
       "  8,\n",
       "  18319,\n",
       "  22117,\n",
       "  41594,\n",
       "  23283,\n",
       "  279,\n",
       "  5055,\n",
       "  20761,\n",
       "  14872,\n",
       "  320,\n",
       "  45,\n",
       "  6754,\n",
       "  8,\n",
       "  18319,\n",
       "  12740,\n",
       "  44167,\n",
       "  220,\n",
       "  17,\n",
       "  19,\n",
       "  4142,\n",
       "  16,\n",
       "  15,\n",
       "  311,\n",
       "  7232,\n",
       "  862,\n",
       "  4843,\n",
       "  7297,\n",
       "  20288,\n",
       "  2265,\n",
       "  13,\n",
       "  576,\n",
       "  1809,\n",
       "  572,\n",
       "  6342,\n",
       "  389,\n",
       "  7400,\n",
       "  220,\n",
       "  22,\n",
       "  11,\n",
       "  220,\n",
       "  17,\n",
       "  15,\n",
       "  16,\n",
       "  21,\n",
       "  11,\n",
       "  518,\n",
       "  55041,\n",
       "  594,\n",
       "  22636,\n",
       "  304,\n",
       "  279,\n",
       "  5836,\n",
       "  12879,\n",
       "  9154,\n",
       "  12030,\n",
       "  518,\n",
       "  15993,\n",
       "  50557,\n",
       "  11,\n",
       "  7043,\n",
       "  13,\n",
       "  1634,\n",
       "  419,\n",
       "  572,\n",
       "  279,\n",
       "  220,\n",
       "  20,\n",
       "  15,\n",
       "  339,\n",
       "  7297,\n",
       "  20288,\n",
       "  11,\n",
       "  279,\n",
       "  10734,\n",
       "  45628,\n",
       "  279,\n",
       "  330,\n",
       "  97235,\n",
       "  21582,\n",
       "  1,\n",
       "  448,\n",
       "  5257,\n",
       "  6623,\n",
       "  56589,\n",
       "  27172,\n",
       "  11,\n",
       "  438,\n",
       "  1632,\n",
       "  438,\n",
       "  27092,\n",
       "  9298,\n",
       "  2459,\n",
       "  279,\n",
       "  13815,\n",
       "  315,\n",
       "  34948,\n",
       "  1817,\n",
       "  7297,\n",
       "  20288,\n",
       "  1809,\n",
       "  448,\n",
       "  12751,\n",
       "  7857,\n",
       "  1127,\n",
       "  320,\n",
       "  7995,\n",
       "  892,\n",
       "  279,\n",
       "  1809,\n",
       "  1035,\n",
       "  614,\n",
       "  1012,\n",
       "  3881,\n",
       "  438,\n",
       "  330,\n",
       "  19284,\n",
       "  20288,\n",
       "  444,\n",
       "  3975,\n",
       "  773,\n",
       "  429,\n",
       "  279,\n",
       "  12426,\n",
       "  1410,\n",
       "  72988,\n",
       "  4565,\n",
       "  279,\n",
       "  34117,\n",
       "  7857,\n",
       "  1127,\n",
       "  220,\n",
       "  20,\n",
       "  15,\n",
       "  13,\n",
       "  1464,\n",
       "  15920,\n",
       "  12588,\n",
       "  2083,\n",
       "  15251,\n",
       "  279,\n",
       "  63536,\n",
       "  518,\n",
       "  7297,\n",
       "  20288,\n",
       "  220,\n",
       "  20,\n",
       "  15,\n",
       "  30,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643,\n",
       "  151643]}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized['validation'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7073fa25-4c46-4ecc-b9d3-76d22983baf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = tokenized['train'].select(range(1000))\n",
    "eval_set = tokenized['validation'].select(range(200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ac51bcdb-daca-4eba-b437-4dc0911187ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cc5a7e1e0cb4af8acd9b4769b00d13c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/681 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b01b619a90148a89637b3f43bdf4840",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c346d009a39f49a5a904f3d637f204a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/138 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "base_model = AutoModelForCausalLM.from_pretrained(model_name).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6da19b56-f055-45bc-ba9a-2280422c09d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate questions\n",
    "def generate_question(context, model, tokenizer, max_new_tokens=30):\n",
    "    input_text = f\"Generate a question: {context} -> \"\n",
    "    inputs = tokenizer(\n",
    "        input_text,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=256,\n",
    "        truncation=True\n",
    "    ).to(model.device)\n",
    "    question_ids = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        attention_mask=inputs[\"attention_mask\"],\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        num_beams=4,\n",
    "        early_stopping=True,\n",
    "        pad_token_id=tokenizer.pad_token_id\n",
    "    )\n",
    "    question = tokenizer.decode(question_ids[0], skip_special_tokens=True)\n",
    "    # Extract question after \"->\"\n",
    "    question = question.split(\"->\")[-1].strip()\n",
    "    return question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4ea2b18f-f7ff-47f1-abea-5e974512a637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate base model\n",
    "scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "base_bleu_scores = []\n",
    "base_rouge_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fddee684-a89c-4dea-a748-ca761da20ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten validation dataset for evaluation\n",
    "eval_contexts = []\n",
    "eval_questions = []\n",
    "for example in dataset[\"validation\"]:\n",
    "    eval_contexts.append(example['context'])\n",
    "    eval_questions.append(example['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8bee7b77-f733-4848-ae1b-aacac7b8c49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0e66c7ea-58b2-41c8-a940-6e222ce03607",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 200/200 [28:38<00:00,  8.59s/it]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on subset\n",
    "for i in tqdm(range(len(eval_set))):  # Match small_eval size\n",
    "    context = eval_contexts[i]\n",
    "    reference = eval_questions[i]\n",
    "    question = generate_question(context, base_model, tokenizer)\n",
    "    # BLEU score\n",
    "    bleu_score = sentence_bleu(reference.split(), question.split())\n",
    "    base_bleu_scores.append(bleu_score)\n",
    "    # ROUGE-L score\n",
    "    rouge_score = scorer.score(reference, question)[\"rougeL\"].fmeasure\n",
    "    base_rouge_scores.append(rouge_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "0764a407-9dc1-4a01-bba1-d069eef67a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Model Scores: {'bleu': np.float64(2.185774629528745e-232), 'rougeL': np.float64(0.15532109414983492)}\n"
     ]
    }
   ],
   "source": [
    "# Compute average scores\n",
    "base_bleu_avg = np.mean(base_bleu_scores)\n",
    "base_rouge_avg = np.mean(base_rouge_scores)\n",
    "print(\"Base Model Scores:\", {\"bleu\": base_bleu_avg, \"rougeL\": base_rouge_avg})\n",
    "\n",
    "# Log to W&B\n",
    "wandb.log({\"base_bleu\": base_bleu_avg, \"base_rougeL\": base_rouge_avg})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90374459-d7e8-4180-bbd9-bcdd35d5ee14",
   "metadata": {},
   "source": [
    "### Tuning part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e9bb81bc-fbb4-4067-891f-03577044d170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Configure Prefix Tuning\n",
    "# Define prefix tuning configuration\n",
    "peft_config = PrefixTuningConfig(\n",
    "    task_type=\"CAUSAL_LM\",\n",
    "    num_virtual_tokens=20,\n",
    "    prefix_projection=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "ebf3da2a-21d3-4204-bcb7-8466b97d0838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 811,648 || all params: 494,844,416 || trainable%: 0.1640\n"
     ]
    }
   ],
   "source": [
    "# Load model and apply prefix tuning\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model = get_peft_model(model, peft_config)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# Move to GPU if available\n",
    "model = model.to(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a5427942-1bd3-4525-8642-f96745158b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Define Metrics and Training Arguments\n",
    "# Compute BLEU and ROUGE metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    # Extract question part after \"->\"\n",
    "    decoded_preds = [pred.split(\"->\")[-1].strip() if \"->\" in pred else pred for pred in decoded_preds]\n",
    "    decoded_labels = [label.split(\"->\")[-1].strip() if \"->\" in label else label for label in decoded_labels]\n",
    "    scorer = rouge_scorer.RougeScorer([\"rougeL\"], use_stemmer=True)\n",
    "    bleu_scores = []\n",
    "    rouge_scores = []\n",
    "    for pred, ref in zip(decoded_preds, decoded_labels):\n",
    "        bleu_scores.append(sentence_bleu([ref.split()], pred.split()))\n",
    "        rouge_scores.append(scorer.score(ref, pred)[\"rougeL\"].f1)\n",
    "    return {\n",
    "        \"bleu\": np.mean(bleu_scores),\n",
    "        \"rougeL\": np.mean(rouge_scores)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "5e2c79e1-d46c-4083-bc52-d634f1875785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\venv-slm-fine-tune\\Lib\\site-packages\\~afetensors'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\venv-slm-fine-tune\\Lib\\site-packages\\~aml'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\venv-slm-fine-tune\\Lib\\site-packages\\~sutil'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\venv-slm-fine-tune\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\venv-slm-fine-tune\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\venv-slm-fine-tune\\Lib\\site-packages\\~arkupsafe'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\venv-slm-fine-tune\\Lib\\site-packages\\~harset_normalizer'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\venv-slm-fine-tune\\Lib\\site-packages\\~orch'.\n",
      "  You can safely remove it manually.\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\venv-slm-fine-tune\\Lib\\site-packages)\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.5.1 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\n",
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --force-reinstall accelerate>=0.26.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f64ea10c-2d01-4adf-afe9-3883e7757ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e974f0f-649a-4846-9fdb-2a4ee2b74a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./qwen25-0.5b-prefix-tuning\",\n",
    "    learning_rate=1e-3,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    push_to_hub=True,\n",
    "    report_to=\"wandb\",\n",
    "    run_name=\"qwen25-0.5b-prefix-tuning\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ac6907-7a94-4da7-8daf-199e0e5e8890",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9f349c-c489-4a87-b2fb-d21effd03a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train,\n",
    "    eval_dataset=small_eval,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a72cfb-e306-4e4e-8d59-29a661c8376b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f366702-5c66-415a-be26-ff1754bd2a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate prefix-tuned model\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Prefix-Tuned Model Scores:\", eval_results)\n",
    "\n",
    "# Log to W&B\n",
    "wandb.log({\n",
    "    \"prefix_bleu\": eval_results[\"eval_bleu\"],\n",
    "    \"prefix_rougeL\": eval_results[\"eval_rougeL\"]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09543d0-233b-47bf-83bd-8edba17379d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare with base model\n",
    "print(\"\\nComparison:\")\n",
    "print(f\"Base Model - BLEU: {base_bleu_avg:.4f}, ROUGE-L: {base_rouge_avg:.4f}\")\n",
    "print(f\"Prefix-Tuned - BLEU: {eval_results['eval_bleu']:.4f}, ROUGE-L: {eval_results['eval_rougeL']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8abbe400-34aa-462e-a44a-db8107287b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Push model to Hugging Face Hub\n",
    "trainer.push_to_hub(\"qwen25-0.5b-prefix-tuning-question-generation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204f0942-da73-4799-a407-5bd78933395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish W&B run\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
