{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09c27178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative GGUF Conversion Using HF-Specific Tools\n",
    "\n",
    "import os\n",
    "from huggingface_hub import login\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel, PeftConfig\n",
    "from dotenv import load_dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c39c3869",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(override=True)\n",
    "\n",
    "assert(os.getenv('hf_token'))\n",
    "assert(os.getenv('WANDB_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74ea28c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Replace with your actual repository names\n",
    "LORA_MODEL_PATH = \"rtweera/qwen_choreo_ft_lora\"  # Update this path!\n",
    "BASE_MODEL_PATH = \"Qwen/Qwen2.5-0.5B-Instruct\"\n",
    "OUTPUT_MODEL_PATH = \"./qwen_choreo_merged\"\n",
    "HF_OUTPUT_REPO = \"rtweera/qwen_choreo_merged\"  # Update this!\n",
    "\n",
    "# Login to Hugging Face\n",
    "login(token=os.getenv('hf_token'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "254f12f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and merging models...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23266ff978a440fabc66436ef3d5a49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\venv-slm-fine-tune\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Ravindu\\.cache\\huggingface\\hub\\models--Qwen--Qwen2.5-0.5B-Instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0108a46e6b487fa77fb4ab70a9c88e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f8d627439144870a0433fe2d2417a5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d0f83c02a834962b091ebcab9149dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bb45eed741f40af95122c7e72eb90bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dff17100fea44ed8c8109247084c681",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04fc19cfbc6459c8c4270212f869876",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39a546396a5e46259a96c60a932e660b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json:   0%|          | 0.00/749 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\venv-slm-fine-tune\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Ravindu\\.cache\\huggingface\\hub\\models--rtweera--qwen_choreo_ft_lora. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612dfca7d281467aa6b480a66378602c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/4.35M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "print(\"Loading and merging models...\")\n",
    "# Load base model and tokenizer\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    BASE_MODEL_PATH,\n",
    "    torch_dtype=torch.float16,  # Use float16 for compatibility with conversion tools\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL_PATH)\n",
    "\n",
    "# Load LoRA and merge\n",
    "peft_model = PeftModel.from_pretrained(base_model, LORA_MODEL_PATH)\n",
    "merged_model = peft_model.merge_and_unload()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67afc23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving merged model...\n",
      "Pushing merged model to Hugging Face Hub...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b06f3ba0e4f4c448b820c5f375b1774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7a2deec8a9742c986b2a0c2a28fa63d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/5.17k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\venv-slm-fine-tune\\Lib\\site-packages\\huggingface_hub\\file_download.py:144: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Ravindu\\.cache\\huggingface\\hub\\models--rtweera--qwen_choreo_merged. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d991aed12e2548c0baa0a5c3a0b1c01d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged model successfully pushed to Hugging Face Hub!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Saving merged model...\")\n",
    "# Save the merged model locally\n",
    "merged_model.save_pretrained(OUTPUT_MODEL_PATH, safe_serialization=True)\n",
    "tokenizer.save_pretrained(OUTPUT_MODEL_PATH)\n",
    "\n",
    "print(\"Pushing merged model to Hugging Face Hub...\")\n",
    "# Push the merged model to Hugging Face Hub\n",
    "merged_model.push_to_hub(HF_OUTPUT_REPO)\n",
    "tokenizer.push_to_hub(HF_OUTPUT_REPO)\n",
    "\n",
    "print(\"Merged model successfully pushed to Hugging Face Hub!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34c954b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Git hooks.\n",
      "Git LFS initialized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'qwen_choreo_merged' already exists and is not an empty directory.\n",
      "fatal: destination path 'llama.cpp' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "# Make sure you have git-lfs installed (https://git-lfs.com)\n",
    "!git lfs install\n",
    "# Clone your model from Huggingface\n",
    "!git clone https://huggingface.co/rtweera/qwen_choreo_merged\n",
    "# Clone llama.cpp's repository. They provide code to convert models into gguf.\n",
    "!git clone https://github.com/ggerganov/llama.cpp.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9b1deda4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\Ravindu\\\\Documents\\\\My Projects\\\\slm-fine-tune\\\\choreo-doc-assistant\\\\notebooks'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b0aa14d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/cpu, https://download.pytorch.org/whl/cpu\n",
      "Collecting numpy~=1.26.4 (from -r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-convert_legacy_llama.txt (line 1))\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Collecting sentencepiece~=0.2.0 (from -r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-convert_legacy_llama.txt (line 2))\n",
      "  Using cached sentencepiece-0.2.0-cp312-cp312-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.45.1 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from -r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-convert_legacy_llama.txt (line 3)) (4.51.3)\n",
      "Collecting gguf>=0.1.0 (from -r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-convert_legacy_llama.txt (line 4))\n",
      "  Downloading gguf-0.16.3-py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting protobuf<5.0.0,>=4.21.0 (from -r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-convert_legacy_llama.txt (line 5))\n",
      "  Downloading protobuf-4.25.7-cp310-abi3-win_amd64.whl.metadata (541 bytes)\n",
      "Collecting torch~=2.2.1 (from -r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-convert_hf_to_gguf.txt (line 3))\n",
      "  Downloading https://download.pytorch.org/whl/cpu/torch-2.2.2%2Bcpu-cp312-cp312-win_amd64.whl (200.7 MB)\n",
      "     ---------------------------------------- 0.0/200.7 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.8/200.7 MB 6.7 MB/s eta 0:00:30\n",
      "      --------------------------------------- 2.6/200.7 MB 7.6 MB/s eta 0:00:27\n",
      "     - -------------------------------------- 5.2/200.7 MB 9.1 MB/s eta 0:00:22\n",
      "     - -------------------------------------- 7.6/200.7 MB 9.8 MB/s eta 0:00:20\n",
      "     - -------------------------------------- 9.7/200.7 MB 9.7 MB/s eta 0:00:20\n",
      "     -- ----------------------------------- 12.1/200.7 MB 10.1 MB/s eta 0:00:19\n",
      "     -- ----------------------------------- 14.7/200.7 MB 10.3 MB/s eta 0:00:19\n",
      "     --- ---------------------------------- 17.0/200.7 MB 10.4 MB/s eta 0:00:18\n",
      "     --- ---------------------------------- 19.4/200.7 MB 10.5 MB/s eta 0:00:18\n",
      "     ---- --------------------------------- 21.5/200.7 MB 10.5 MB/s eta 0:00:18\n",
      "     ---- --------------------------------- 23.3/200.7 MB 10.3 MB/s eta 0:00:18\n",
      "     ---- --------------------------------- 24.9/200.7 MB 10.0 MB/s eta 0:00:18\n",
      "     ----- -------------------------------- 27.5/200.7 MB 10.1 MB/s eta 0:00:18\n",
      "     ----- -------------------------------- 29.9/200.7 MB 10.2 MB/s eta 0:00:17\n",
      "     ------ ------------------------------- 32.5/200.7 MB 10.4 MB/s eta 0:00:17\n",
      "     ------ ------------------------------- 34.9/200.7 MB 10.4 MB/s eta 0:00:16\n",
      "     ------- ------------------------------ 37.2/200.7 MB 10.5 MB/s eta 0:00:16\n",
      "     ------- ------------------------------ 38.8/200.7 MB 10.3 MB/s eta 0:00:16\n",
      "     ------- ------------------------------ 40.9/200.7 MB 10.2 MB/s eta 0:00:16\n",
      "     -------- ----------------------------- 42.7/200.7 MB 10.2 MB/s eta 0:00:16\n",
      "     -------- ----------------------------- 44.8/200.7 MB 10.2 MB/s eta 0:00:16\n",
      "     -------- ----------------------------- 46.9/200.7 MB 10.1 MB/s eta 0:00:16\n",
      "     --------- ---------------------------- 48.8/200.7 MB 10.1 MB/s eta 0:00:16\n",
      "     --------- ---------------------------- 50.6/200.7 MB 10.0 MB/s eta 0:00:15\n",
      "     ---------- --------------------------- 53.2/200.7 MB 10.1 MB/s eta 0:00:15\n",
      "     ---------- --------------------------- 55.6/200.7 MB 10.1 MB/s eta 0:00:15\n",
      "     ----------- -------------------------- 58.2/200.7 MB 10.2 MB/s eta 0:00:14\n",
      "     ----------- -------------------------- 60.6/200.7 MB 10.2 MB/s eta 0:00:14\n",
      "     ----------- -------------------------- 62.4/200.7 MB 10.2 MB/s eta 0:00:14\n",
      "     ------------ ------------------------- 65.3/200.7 MB 10.2 MB/s eta 0:00:14\n",
      "     ------------ ------------------------- 67.9/200.7 MB 10.3 MB/s eta 0:00:13\n",
      "     ------------- ------------------------ 69.5/200.7 MB 10.3 MB/s eta 0:00:13\n",
      "     ------------- ------------------------ 71.8/200.7 MB 10.3 MB/s eta 0:00:13\n",
      "     ------------- ------------------------ 73.9/200.7 MB 10.3 MB/s eta 0:00:13\n",
      "     -------------- ----------------------- 75.5/200.7 MB 10.2 MB/s eta 0:00:13\n",
      "     -------------- ----------------------- 77.1/200.7 MB 10.1 MB/s eta 0:00:13\n",
      "     -------------- ----------------------- 78.6/200.7 MB 10.0 MB/s eta 0:00:13\n",
      "     --------------- ----------------------- 80.2/200.7 MB 9.9 MB/s eta 0:00:13\n",
      "     --------------- ----------------------- 82.3/200.7 MB 9.9 MB/s eta 0:00:12\n",
      "     ---------------- --------------------- 84.9/200.7 MB 10.0 MB/s eta 0:00:12\n",
      "     ---------------- --------------------- 86.8/200.7 MB 10.0 MB/s eta 0:00:12\n",
      "     ---------------- --------------------- 89.4/200.7 MB 10.0 MB/s eta 0:00:12\n",
      "     ----------------- -------------------- 92.0/200.7 MB 10.1 MB/s eta 0:00:11\n",
      "     ----------------- -------------------- 94.6/200.7 MB 10.1 MB/s eta 0:00:11\n",
      "     ------------------ ------------------- 95.9/200.7 MB 10.1 MB/s eta 0:00:11\n",
      "     ------------------ -------------------- 96.7/200.7 MB 9.9 MB/s eta 0:00:11\n",
      "     ------------------- ------------------- 99.1/200.7 MB 9.9 MB/s eta 0:00:11\n",
      "     ------------------ ------------------ 101.7/200.7 MB 10.0 MB/s eta 0:00:10\n",
      "     ------------------- ------------------ 103.8/200.7 MB 9.9 MB/s eta 0:00:10\n",
      "     ------------------- ----------------- 106.4/200.7 MB 10.0 MB/s eta 0:00:10\n",
      "     -------------------- ---------------- 109.1/200.7 MB 10.0 MB/s eta 0:00:10\n",
      "     -------------------- ---------------- 111.1/200.7 MB 10.0 MB/s eta 0:00:09\n",
      "     -------------------- ---------------- 113.8/200.7 MB 10.1 MB/s eta 0:00:09\n",
      "     --------------------- --------------- 116.4/200.7 MB 10.1 MB/s eta 0:00:09\n",
      "     --------------------- --------------- 119.0/200.7 MB 10.2 MB/s eta 0:00:09\n",
      "     ---------------------- -------------- 121.4/200.7 MB 10.2 MB/s eta 0:00:08\n",
      "     ---------------------- -------------- 124.3/200.7 MB 10.2 MB/s eta 0:00:08\n",
      "     ----------------------- ------------- 126.9/200.7 MB 10.3 MB/s eta 0:00:08\n",
      "     ----------------------- ------------- 129.5/200.7 MB 10.3 MB/s eta 0:00:07\n",
      "     ------------------------ ------------ 132.4/200.7 MB 10.3 MB/s eta 0:00:07\n",
      "     ------------------------ ------------ 135.0/200.7 MB 10.4 MB/s eta 0:00:07\n",
      "     ------------------------- ----------- 137.4/200.7 MB 10.4 MB/s eta 0:00:07\n",
      "     ------------------------- ----------- 140.0/200.7 MB 10.4 MB/s eta 0:00:06\n",
      "     -------------------------- ---------- 142.6/200.7 MB 10.4 MB/s eta 0:00:06\n",
      "     -------------------------- ---------- 145.5/200.7 MB 10.5 MB/s eta 0:00:06\n",
      "     --------------------------- --------- 148.1/200.7 MB 10.5 MB/s eta 0:00:06\n",
      "     --------------------------- --------- 150.5/200.7 MB 10.5 MB/s eta 0:00:05\n",
      "     ---------------------------- -------- 153.1/200.7 MB 10.6 MB/s eta 0:00:05\n",
      "     ---------------------------- -------- 155.7/200.7 MB 10.6 MB/s eta 0:00:05\n",
      "     ----------------------------- ------- 158.1/200.7 MB 10.6 MB/s eta 0:00:05\n",
      "     ----------------------------- ------- 160.7/200.7 MB 10.6 MB/s eta 0:00:04\n",
      "     ------------------------------ ------ 163.6/200.7 MB 10.6 MB/s eta 0:00:04\n",
      "     ------------------------------ ------ 166.2/200.7 MB 10.7 MB/s eta 0:00:04\n",
      "     ------------------------------- ----- 168.3/200.7 MB 10.7 MB/s eta 0:00:04\n",
      "     ------------------------------- ----- 170.1/200.7 MB 10.7 MB/s eta 0:00:03\n",
      "     ------------------------------- ----- 172.2/200.7 MB 10.6 MB/s eta 0:00:03\n",
      "     -------------------------------- ---- 174.3/200.7 MB 10.6 MB/s eta 0:00:03\n",
      "     -------------------------------- ---- 176.2/200.7 MB 10.6 MB/s eta 0:00:03\n",
      "     -------------------------------- ---- 178.3/200.7 MB 10.6 MB/s eta 0:00:03\n",
      "     --------------------------------- --- 180.4/200.7 MB 10.6 MB/s eta 0:00:02\n",
      "     --------------------------------- --- 182.7/200.7 MB 10.6 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 185.6/200.7 MB 10.6 MB/s eta 0:00:02\n",
      "     ---------------------------------- -- 188.2/200.7 MB 10.6 MB/s eta 0:00:02\n",
      "     ----------------------------------- - 190.8/200.7 MB 10.6 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 193.5/200.7 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  196.1/200.7 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  199.0/200.7 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  200.5/200.7 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  200.5/200.7 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  200.5/200.7 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  200.5/200.7 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  200.5/200.7 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  200.5/200.7 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  200.5/200.7 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  200.5/200.7 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  200.5/200.7 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  200.5/200.7 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  200.5/200.7 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  200.5/200.7 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  200.5/200.7 MB 10.7 MB/s eta 0:00:01\n",
      "     ------------------------------------  200.5/200.7 MB 10.7 MB/s eta 0:00:01\n",
      "     -------------------------------------- 200.7/200.7 MB 9.3 MB/s eta 0:00:00\n",
      "Collecting aiohttp~=3.9.3 (from -r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 1))\n",
      "  Downloading aiohttp-3.9.5-cp312-cp312-win_amd64.whl.metadata (7.7 kB)\n",
      "Collecting pytest~=8.3.3 (from -r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 2))\n",
      "  Using cached pytest-8.3.5-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting huggingface_hub~=0.23.2 (from -r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 3))\n",
      "  Downloading huggingface_hub-0.23.5-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: matplotlib~=3.10.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from -r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 4)) (3.10.1)\n",
      "Collecting openai~=1.55.3 (from -r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 6))\n",
      "  Downloading openai-1.55.3-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: pandas~=2.2.3 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from -r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 7)) (2.2.3)\n",
      "Collecting prometheus-client~=0.20.0 (from -r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 8))\n",
      "  Downloading prometheus_client-0.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: requests~=2.32.3 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from -r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 9)) (2.32.3)\n",
      "Collecting wget~=3.2 (from -r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 10))\n",
      "  Downloading wget-3.2.zip (10 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting typer~=0.15.1 (from -r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 11))\n",
      "  Downloading typer-0.15.4-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting seaborn~=0.13.2 (from -r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 12))\n",
      "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from transformers<5.0.0,>=4.45.1->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-convert_legacy_llama.txt (line 3)) (3.18.0)\n",
      "INFO: pip is looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting transformers<5.0.0,>=4.45.1 (from -r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-convert_legacy_llama.txt (line 3))\n",
      "  Downloading transformers-4.51.2-py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading transformers-4.51.1-py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading transformers-4.51.0-py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
      "  Downloading transformers-4.50.2-py3-none-any.whl.metadata (39 kB)\n",
      "  Using cached transformers-4.50.1-py3-none-any.whl.metadata (39 kB)\n",
      "  Using cached transformers-4.50.0-py3-none-any.whl.metadata (39 kB)\n",
      "INFO: pip is still looking at multiple versions of transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading transformers-4.49.0-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.48.3-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.48.2-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.48.1-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.48.0-py3-none-any.whl.metadata (44 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading transformers-4.47.1-py3-none-any.whl.metadata (44 kB)\n",
      "  Downloading transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading transformers-4.46.3-py3-none-any.whl.metadata (44 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from transformers<5.0.0,>=4.45.1->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-convert_legacy_llama.txt (line 3)) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from transformers<5.0.0,>=4.45.1->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-convert_legacy_llama.txt (line 3)) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from transformers<5.0.0,>=4.45.1->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-convert_legacy_llama.txt (line 3)) (2024.11.6)\n",
      "Collecting tokenizers<0.21,>=0.20 (from transformers<5.0.0,>=4.45.1->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-convert_legacy_llama.txt (line 3))\n",
      "  Downloading tokenizers-0.20.3-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from transformers<5.0.0,>=4.45.1->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-convert_legacy_llama.txt (line 3)) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from transformers<5.0.0,>=4.45.1->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-convert_legacy_llama.txt (line 3)) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from torch~=2.2.1->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-convert_hf_to_gguf.txt (line 3)) (4.13.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from torch~=2.2.1->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-convert_hf_to_gguf.txt (line 3)) (1.14.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from torch~=2.2.1->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-convert_hf_to_gguf.txt (line 3)) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from torch~=2.2.1->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-convert_hf_to_gguf.txt (line 3)) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from torch~=2.2.1->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-convert_hf_to_gguf.txt (line 3)) (2025.3.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from aiohttp~=3.9.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 1)) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from aiohttp~=3.9.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 1)) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from aiohttp~=3.9.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 1)) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from aiohttp~=3.9.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 1)) (6.4.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from aiohttp~=3.9.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 1)) (1.20.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from pytest~=8.3.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 2)) (0.4.6)\n",
      "Collecting iniconfig (from pytest~=8.3.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 2))\n",
      "  Using cached iniconfig-2.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: pluggy<2,>=1.5 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from pytest~=8.3.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 2)) (1.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from matplotlib~=3.10.0->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 4)) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from matplotlib~=3.10.0->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from matplotlib~=3.10.0->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 4)) (4.57.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from matplotlib~=3.10.0->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 4)) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from matplotlib~=3.10.0->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 4)) (11.2.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from matplotlib~=3.10.0->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 4)) (3.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from matplotlib~=3.10.0->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 4)) (2.9.0.post0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from openai~=1.55.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 6)) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai~=1.55.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 6))\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from openai~=1.55.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 6)) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai~=1.55.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 6))\n",
      "  Using cached jiter-0.9.0-cp312-cp312-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from openai~=1.55.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 6)) (2.11.3)\n",
      "Requirement already satisfied: sniffio in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from openai~=1.55.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from pandas~=2.2.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 7)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from pandas~=2.2.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 7)) (2025.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from requests~=2.32.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 9)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from requests~=2.32.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 9)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from requests~=2.32.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 9)) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from requests~=2.32.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 9)) (2025.4.26)\n",
      "Requirement already satisfied: click<8.2,>=8.0.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from typer~=0.15.1->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 11)) (8.1.8)\n",
      "Collecting shellingham>=1.3.0 (from typer~=0.15.1->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 11))\n",
      "  Using cached shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from typer~=0.15.1->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 11)) (13.9.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from httpx<1,>=0.23.0->openai~=1.55.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 6)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai~=1.55.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 6)) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from pydantic<3,>=1.9.0->openai~=1.55.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 6)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from pydantic<3,>=1.9.0->openai~=1.55.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 6)) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from pydantic<3,>=1.9.0->openai~=1.55.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 6)) (0.4.0)\n",
      "Requirement already satisfied: propcache>=0.2.1 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from yarl<2.0,>=1.0->aiohttp~=3.9.3->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 1)) (0.3.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from python-dateutil>=2.7->matplotlib~=3.10.0->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 4)) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from rich>=10.11.0->typer~=0.15.1->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 11)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from rich>=10.11.0->typer~=0.15.1->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 11)) (2.19.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer~=0.15.1->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-tool_bench.txt (line 11)) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from jinja2->torch~=2.2.1->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-convert_hf_to_gguf.txt (line 3)) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ravindu\\documents\\my projects\\slm-fine-tune\\venv-slm-fine-tune\\lib\\site-packages (from sympy->torch~=2.2.1->-r c:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\choreo-doc-assistant\\notebooks\\llama.cpp\\requirements\\requirements-convert_hf_to_gguf.txt (line 3)) (1.3.0)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Using cached sentencepiece-0.2.0-cp312-cp312-win_amd64.whl (991 kB)\n",
      "Downloading transformers-4.46.3-py3-none-any.whl (10.0 MB)\n",
      "   ---------------------------------------- 0.0/10.0 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.5/10.0 MB 4.2 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 2.9/10.0 MB 8.8 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 5.5/10.0 MB 10.2 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 7.9/10.0 MB 10.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.0/10.0 MB 10.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.0/10.0 MB 7.9 MB/s eta 0:00:00\n",
      "Downloading protobuf-4.25.7-cp310-abi3-win_amd64.whl (413 kB)\n",
      "Downloading aiohttp-3.9.5-cp312-cp312-win_amd64.whl (369 kB)\n",
      "Using cached pytest-8.3.5-py3-none-any.whl (343 kB)\n",
      "Downloading huggingface_hub-0.23.5-py3-none-any.whl (402 kB)\n",
      "Downloading openai-1.55.3-py3-none-any.whl (389 kB)\n",
      "Downloading prometheus_client-0.20.0-py3-none-any.whl (54 kB)\n",
      "Downloading typer-0.15.4-py3-none-any.whl (45 kB)\n",
      "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Using cached jiter-0.9.0-cp312-cp312-win_amd64.whl (207 kB)\n",
      "Downloading tokenizers-0.20.3-cp312-none-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ---------------------------------------  2.4/2.4 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 8.0 MB/s eta 0:00:00\n",
      "Downloading gguf-0.16.3-py3-none-any.whl (94 kB)\n",
      "Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Using cached iniconfig-2.1.0-py3-none-any.whl (6.0 kB)\n",
      "Building wheels for collected packages: wget\n",
      "  Building wheel for wget (pyproject.toml): started\n",
      "  Building wheel for wget (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9711 sha256=ce4aad66d60e58128b92a7f3ccf2381c029fc20920a355ab4aa94bc17c8ffcaa\n",
      "  Stored in directory: c:\\users\\ravindu\\appdata\\local\\pip\\cache\\wheels\\01\\46\\3b\\e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9\n",
      "Successfully built wget\n",
      "Installing collected packages: wget, sentencepiece, shellingham, protobuf, prometheus-client, numpy, jiter, iniconfig, distro, torch, pytest, huggingface_hub, gguf, aiohttp, typer, tokenizers, openai, transformers, seaborn\n",
      "\n",
      "   ---- -----------------------------------  2/19 [shellingham]\n",
      "  Attempting uninstall: protobuf\n",
      "   ---- -----------------------------------  2/19 [shellingham]\n",
      "    Found existing installation: protobuf 5.29.4\n",
      "   ---- -----------------------------------  2/19 [shellingham]\n",
      "    Uninstalling protobuf-5.29.4:\n",
      "   ---- -----------------------------------  2/19 [shellingham]\n",
      "      Successfully uninstalled protobuf-5.29.4\n",
      "   ---- -----------------------------------  2/19 [shellingham]\n",
      "   ------ ---------------------------------  3/19 [protobuf]\n",
      "   ------ ---------------------------------  3/19 [protobuf]\n",
      "   ------ ---------------------------------  3/19 [protobuf]\n",
      "  Attempting uninstall: prometheus-client\n",
      "   ------ ---------------------------------  3/19 [protobuf]\n",
      "    Found existing installation: prometheus_client 0.21.1\n",
      "   ------ ---------------------------------  3/19 [protobuf]\n",
      "    Uninstalling prometheus_client-0.21.1:\n",
      "   ------ ---------------------------------  3/19 [protobuf]\n",
      "      Successfully uninstalled prometheus_client-0.21.1\n",
      "   ------ ---------------------------------  3/19 [protobuf]\n",
      "   -------- -------------------------------  4/19 [prometheus-client]\n",
      "  Attempting uninstall: numpy\n",
      "   -------- -------------------------------  4/19 [prometheus-client]\n",
      "    Found existing installation: numpy 2.2.5\n",
      "   -------- -------------------------------  4/19 [prometheus-client]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "    Uninstalling numpy-2.2.5:\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "      Successfully uninstalled numpy-2.2.5\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ---------- -----------------------------  5/19 [numpy]\n",
      "   ------------ ---------------------------  6/19 [jiter]\n",
      "  Attempting uninstall: torch\n",
      "   ------------ ---------------------------  6/19 [jiter]\n",
      "    Found existing installation: torch 2.7.0\n",
      "   ------------ ---------------------------  6/19 [jiter]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "    Uninstalling torch-2.7.0:\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "      Successfully uninstalled torch-2.7.0\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   ------------------ ---------------------  9/19 [torch]\n",
      "   --------------------- ------------------ 10/19 [pytest]\n",
      "   --------------------- ------------------ 10/19 [pytest]\n",
      "   --------------------- ------------------ 10/19 [pytest]\n",
      "   --------------------- ------------------ 10/19 [pytest]\n",
      "   --------------------- ------------------ 10/19 [pytest]\n",
      "   --------------------- ------------------ 10/19 [pytest]\n",
      "   --------------------- ------------------ 10/19 [pytest]\n",
      "   --------------------- ------------------ 10/19 [pytest]\n",
      "   --------------------- ------------------ 10/19 [pytest]\n",
      "   --------------------- ------------------ 10/19 [pytest]\n",
      "  Attempting uninstall: huggingface_hub\n",
      "   --------------------- ------------------ 10/19 [pytest]\n",
      "    Found existing installation: huggingface-hub 0.30.2\n",
      "   --------------------- ------------------ 10/19 [pytest]\n",
      "   ----------------------- ---------------- 11/19 [huggingface_hub]\n",
      "    Uninstalling huggingface-hub-0.30.2:\n",
      "   ----------------------- ---------------- 11/19 [huggingface_hub]\n",
      "      Successfully uninstalled huggingface-hub-0.30.2\n",
      "   ----------------------- ---------------- 11/19 [huggingface_hub]\n",
      "   ----------------------- ---------------- 11/19 [huggingface_hub]\n",
      "   ----------------------- ---------------- 11/19 [huggingface_hub]\n",
      "   ----------------------- ---------------- 11/19 [huggingface_hub]\n",
      "   ----------------------- ---------------- 11/19 [huggingface_hub]\n",
      "   ----------------------- ---------------- 11/19 [huggingface_hub]\n",
      "   ----------------------- ---------------- 11/19 [huggingface_hub]\n",
      "   ----------------------- ---------------- 11/19 [huggingface_hub]\n",
      "   ----------------------- ---------------- 11/19 [huggingface_hub]\n",
      "   ----------------------- ---------------- 11/19 [huggingface_hub]\n",
      "   ------------------------- -------------- 12/19 [gguf]\n",
      "   ------------------------- -------------- 12/19 [gguf]\n",
      "  Attempting uninstall: aiohttp\n",
      "   ------------------------- -------------- 12/19 [gguf]\n",
      "    Found existing installation: aiohttp 3.11.18\n",
      "   ------------------------- -------------- 12/19 [gguf]\n",
      "   --------------------------- ------------ 13/19 [aiohttp]\n",
      "    Uninstalling aiohttp-3.11.18:\n",
      "   --------------------------- ------------ 13/19 [aiohttp]\n",
      "      Successfully uninstalled aiohttp-3.11.18\n",
      "   --------------------------- ------------ 13/19 [aiohttp]\n",
      "   --------------------------- ------------ 13/19 [aiohttp]\n",
      "   --------------------------- ------------ 13/19 [aiohttp]\n",
      "   --------------------------- ------------ 13/19 [aiohttp]\n",
      "   --------------------------- ------------ 13/19 [aiohttp]\n",
      "   --------------------------- ------------ 13/19 [aiohttp]\n",
      "   --------------------------- ------------ 13/19 [aiohttp]\n",
      "   ----------------------------- ---------- 14/19 [typer]\n",
      "  Attempting uninstall: tokenizers\n",
      "   ----------------------------- ---------- 14/19 [typer]\n",
      "    Found existing installation: tokenizers 0.21.1\n",
      "   ----------------------------- ---------- 14/19 [typer]\n",
      "   ------------------------------- -------- 15/19 [tokenizers]\n",
      "    Uninstalling tokenizers-0.21.1:\n",
      "   ------------------------------- -------- 15/19 [tokenizers]\n",
      "      Successfully uninstalled tokenizers-0.21.1\n",
      "   ------------------------------- -------- 15/19 [tokenizers]\n",
      "   ------------------------------- -------- 15/19 [tokenizers]\n",
      "   ------------------------------- -------- 15/19 [tokenizers]\n",
      "   ------------------------------- -------- 15/19 [tokenizers]\n",
      "   ------------------------------- -------- 15/19 [tokenizers]\n",
      "   ------------------------------- -------- 15/19 [tokenizers]\n",
      "   ------------------------------- -------- 15/19 [tokenizers]\n",
      "   ------------------------------- -------- 15/19 [tokenizers]\n",
      "   ------------------------------- -------- 15/19 [tokenizers]\n",
      "   ------------------------------- -------- 15/19 [tokenizers]\n",
      "   ------------------------------- -------- 15/19 [tokenizers]\n",
      "   ------------------------------- -------- 15/19 [tokenizers]\n",
      "   ------------------------------- -------- 15/19 [tokenizers]\n",
      "   ------------------------------- -------- 15/19 [tokenizers]\n",
      "   ------------------------------- -------- 15/19 [tokenizers]\n",
      "   ------------------------------- -------- 15/19 [tokenizers]\n",
      "   ------------------------------- -------- 15/19 [tokenizers]\n",
      "   ------------------------------- -------- 15/19 [tokenizers]\n",
      "   ------------------------------- -------- 15/19 [tokenizers]\n",
      "   ------------------------------- -------- 15/19 [tokenizers]\n",
      "   ------------------------------- -------- 15/19 [tokenizers]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "  Attempting uninstall: transformers\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "    Found existing installation: transformers 4.51.3\n",
      "   --------------------------------- ------ 16/19 [openai]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "    Uninstalling transformers-4.51.3:\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "      Successfully uninstalled transformers-4.51.3\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "  Attempting uninstall: seaborn\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "    Found existing installation: seaborn 0.12.2\n",
      "   ----------------------------------- ---- 17/19 [transformers]\n",
      "   ------------------------------------- -- 18/19 [seaborn]\n",
      "    Uninstalling seaborn-0.12.2:\n",
      "   ------------------------------------- -- 18/19 [seaborn]\n",
      "      Successfully uninstalled seaborn-0.12.2\n",
      "   ------------------------------------- -- 18/19 [seaborn]\n",
      "   ------------------------------------- -- 18/19 [seaborn]\n",
      "   ------------------------------------- -- 18/19 [seaborn]\n",
      "   ------------------------------------- -- 18/19 [seaborn]\n",
      "   ------------------------------------- -- 18/19 [seaborn]\n",
      "   ------------------------------------- -- 18/19 [seaborn]\n",
      "   ------------------------------------- -- 18/19 [seaborn]\n",
      "   ---------------------------------------- 19/19 [seaborn]\n",
      "\n",
      "Successfully installed aiohttp-3.9.5 distro-1.9.0 gguf-0.16.3 huggingface_hub-0.23.5 iniconfig-2.1.0 jiter-0.9.0 numpy-1.26.4 openai-1.55.3 prometheus-client-0.20.0 protobuf-4.25.7 pytest-8.3.5 seaborn-0.13.2 sentencepiece-0.2.0 shellingham-1.5.4 tokenizers-0.20.3 torch-2.2.2+cpu transformers-4.46.3 typer-0.15.4 wget-3.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\venv-slm-fine-tune\\Lib\\site-packages\\~-mpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\venv-slm-fine-tune\\Lib\\site-packages\\~-mpy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\venv-slm-fine-tune\\Lib\\site-packages\\~-rch'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\Ravindu\\Documents\\My Projects\\slm-fine-tune\\venv-slm-fine-tune\\Lib\\site-packages\\~okenizers'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "datasets 3.5.1 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\n",
      "datasets 3.5.1 requires huggingface-hub>=0.24.0, but you have huggingface-hub 0.23.5 which is incompatible.\n",
      "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.7 which is incompatible.\n",
      "peft 0.15.2 requires huggingface_hub>=0.25.0, but you have huggingface-hub 0.23.5 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ./llama.cpp/requirements.txt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6927ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hf-to-gguf:Loading model: qwen_choreo_merged\n",
      "INFO:hf-to-gguf:Model architecture: Qwen2ForCausalLM\n",
      "INFO:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "INFO:hf-to-gguf:Exporting model...\n",
      "INFO:hf-to-gguf:gguf: loading model part 'model.safetensors'\n",
      "INFO:hf-to-gguf:token_embd.weight,         torch.float16 --> Q8_0, shape = {896, 151936}\n",
      "INFO:hf-to-gguf:blk.0.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.0.ffn_down.weight,     torch.float16 --> Q8_0, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.0.ffn_gate.weight,     torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.0.ffn_up.weight,       torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.0.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.0.attn_k.weight,       torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.0.attn_output.weight,  torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.0.attn_q.weight,       torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.0.attn_v.weight,       torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.1.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.1.ffn_down.weight,     torch.float16 --> Q8_0, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.1.ffn_gate.weight,     torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.1.ffn_up.weight,       torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.1.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.1.attn_k.weight,       torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.1.attn_output.weight,  torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.1.attn_q.weight,       torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.1.attn_v.weight,       torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.10.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.10.ffn_down.weight,    torch.float16 --> Q8_0, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.10.ffn_gate.weight,    torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.10.ffn_up.weight,      torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.10.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.10.attn_k.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.10.attn_output.weight, torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.10.attn_q.weight,      torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.10.attn_v.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.11.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.11.ffn_down.weight,    torch.float16 --> Q8_0, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.11.ffn_gate.weight,    torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.11.ffn_up.weight,      torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.11.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.11.attn_k.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.11.attn_output.weight, torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.11.attn_q.weight,      torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.11.attn_v.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.12.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.12.ffn_down.weight,    torch.float16 --> Q8_0, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.12.ffn_gate.weight,    torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.12.ffn_up.weight,      torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.12.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.12.attn_k.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.12.attn_output.weight, torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.12.attn_q.weight,      torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.12.attn_v.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.13.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.13.ffn_down.weight,    torch.float16 --> Q8_0, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.13.ffn_gate.weight,    torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.13.ffn_up.weight,      torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.13.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.13.attn_k.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.13.attn_output.weight, torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.13.attn_q.weight,      torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.13.attn_v.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.14.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.14.ffn_down.weight,    torch.float16 --> Q8_0, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.14.ffn_gate.weight,    torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.14.ffn_up.weight,      torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.14.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.14.attn_k.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.14.attn_output.weight, torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.14.attn_q.weight,      torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.14.attn_v.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.15.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.15.ffn_down.weight,    torch.float16 --> Q8_0, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.15.ffn_gate.weight,    torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.15.ffn_up.weight,      torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.15.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.15.attn_k.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.15.attn_output.weight, torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.15.attn_q.weight,      torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.15.attn_v.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.16.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.16.ffn_down.weight,    torch.float16 --> Q8_0, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.16.ffn_gate.weight,    torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.16.ffn_up.weight,      torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.16.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.16.attn_k.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.16.attn_output.weight, torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.16.attn_q.weight,      torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.16.attn_v.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.17.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.17.ffn_down.weight,    torch.float16 --> Q8_0, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.17.ffn_gate.weight,    torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.17.ffn_up.weight,      torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.17.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.17.attn_k.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.17.attn_output.weight, torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.17.attn_q.weight,      torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.17.attn_v.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.18.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.18.ffn_down.weight,    torch.float16 --> Q8_0, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.18.ffn_gate.weight,    torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.18.ffn_up.weight,      torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.18.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.18.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.18.attn_k.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.18.attn_output.weight, torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.18.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.18.attn_q.weight,      torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.18.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.18.attn_v.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.19.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.19.ffn_down.weight,    torch.float16 --> Q8_0, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.19.ffn_gate.weight,    torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.19.ffn_up.weight,      torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.19.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.19.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.19.attn_k.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.19.attn_output.weight, torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.19.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.19.attn_q.weight,      torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.19.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.19.attn_v.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.2.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.2.ffn_down.weight,     torch.float16 --> Q8_0, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.2.ffn_gate.weight,     torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.2.ffn_up.weight,       torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.2.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.2.attn_k.weight,       torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.2.attn_output.weight,  torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.2.attn_q.weight,       torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.2.attn_v.weight,       torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.20.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.20.ffn_down.weight,    torch.float16 --> Q8_0, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.20.ffn_gate.weight,    torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.20.ffn_up.weight,      torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.20.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.20.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.20.attn_k.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.20.attn_output.weight, torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.20.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.20.attn_q.weight,      torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.20.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.20.attn_v.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.21.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.21.ffn_down.weight,    torch.float16 --> Q8_0, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.21.ffn_gate.weight,    torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.21.ffn_up.weight,      torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.21.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.21.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.21.attn_k.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.21.attn_output.weight, torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.21.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.21.attn_q.weight,      torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.21.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.21.attn_v.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.22.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.22.ffn_down.weight,    torch.float16 --> Q8_0, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.22.ffn_gate.weight,    torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.22.ffn_up.weight,      torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.22.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.22.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.22.attn_k.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.22.attn_output.weight, torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.22.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.22.attn_q.weight,      torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.22.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.22.attn_v.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.23.attn_norm.weight,   torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.23.ffn_down.weight,    torch.float16 --> Q8_0, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.23.ffn_gate.weight,    torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.23.ffn_up.weight,      torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.23.ffn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.23.attn_k.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.23.attn_k.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.23.attn_output.weight, torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.23.attn_q.bias,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.23.attn_q.weight,      torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.23.attn_v.bias,        torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.23.attn_v.weight,      torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.3.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.3.ffn_down.weight,     torch.float16 --> Q8_0, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.3.ffn_gate.weight,     torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.3.ffn_up.weight,       torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.3.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.3.attn_k.weight,       torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.3.attn_output.weight,  torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.3.attn_q.weight,       torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.3.attn_v.weight,       torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.4.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.4.ffn_down.weight,     torch.float16 --> Q8_0, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.4.ffn_gate.weight,     torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.4.ffn_up.weight,       torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.4.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.4.attn_k.weight,       torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.4.attn_output.weight,  torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.4.attn_q.weight,       torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.4.attn_v.weight,       torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.5.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.5.ffn_down.weight,     torch.float16 --> Q8_0, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.5.ffn_gate.weight,     torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.5.ffn_up.weight,       torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.5.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.5.attn_k.weight,       torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.5.attn_output.weight,  torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.5.attn_q.weight,       torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.5.attn_v.weight,       torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.6.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.6.ffn_down.weight,     torch.float16 --> Q8_0, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.6.ffn_gate.weight,     torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.6.ffn_up.weight,       torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.6.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.6.attn_k.weight,       torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.6.attn_output.weight,  torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.6.attn_q.weight,       torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.6.attn_v.weight,       torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.7.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.7.ffn_down.weight,     torch.float16 --> Q8_0, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.7.ffn_gate.weight,     torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.7.ffn_up.weight,       torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.7.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.7.attn_k.weight,       torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.7.attn_output.weight,  torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.7.attn_q.weight,       torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.7.attn_v.weight,       torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.8.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.8.ffn_down.weight,     torch.float16 --> Q8_0, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.8.ffn_gate.weight,     torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.8.ffn_up.weight,       torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.8.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.8.attn_k.weight,       torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.8.attn_output.weight,  torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.8.attn_q.weight,       torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.8.attn_v.weight,       torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.9.attn_norm.weight,    torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.9.ffn_down.weight,     torch.float16 --> Q8_0, shape = {4864, 896}\n",
      "INFO:hf-to-gguf:blk.9.ffn_gate.weight,     torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.9.ffn_up.weight,       torch.float16 --> Q8_0, shape = {896, 4864}\n",
      "INFO:hf-to-gguf:blk.9.ffn_norm.weight,     torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.9.attn_k.weight,       torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:blk.9.attn_output.weight,  torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.bias,         torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:blk.9.attn_q.weight,       torch.float16 --> Q8_0, shape = {896, 896}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.bias,         torch.float16 --> F32, shape = {128}\n",
      "INFO:hf-to-gguf:blk.9.attn_v.weight,       torch.float16 --> Q8_0, shape = {896, 128}\n",
      "INFO:hf-to-gguf:output_norm.weight,        torch.float16 --> F32, shape = {896}\n",
      "INFO:hf-to-gguf:Set meta model\n",
      "INFO:hf-to-gguf:Set model parameters\n",
      "INFO:hf-to-gguf:gguf: context length = 32768\n",
      "INFO:hf-to-gguf:gguf: embedding length = 896\n",
      "INFO:hf-to-gguf:gguf: feed forward length = 4864\n",
      "INFO:hf-to-gguf:gguf: head count = 14\n",
      "INFO:hf-to-gguf:gguf: key-value head count = 2\n",
      "INFO:hf-to-gguf:gguf: rope theta = 1000000.0\n",
      "INFO:hf-to-gguf:gguf: rms norm epsilon = 1e-06\n",
      "INFO:hf-to-gguf:gguf: file type = 7\n",
      "INFO:hf-to-gguf:Set model quantization version\n",
      "INFO:hf-to-gguf:Set model tokenizer\n",
      "INFO:gguf.vocab:Adding 151387 merge(s).\n",
      "INFO:gguf.vocab:Setting special token type eos to 151645\n",
      "INFO:gguf.vocab:Setting special token type pad to 151643\n",
      "INFO:gguf.vocab:Setting special token type bos to 151643\n",
      "INFO:gguf.vocab:Setting add_bos_token to False\n",
      "INFO:gguf.vocab:Setting chat_template to {%- if tools %}\n",
      "    {{- '<|im_start|>system\\n' }}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- messages[0]['content'] }}\n",
      "    {%- else %}\n",
      "        {{- 'You are Qwen, created by Alibaba Cloud. You are a helpful assistant.' }}\n",
      "    {%- endif %}\n",
      "    {{- \"\\n\\n# Tools\\n\\nYou may call one or more functions to assist with the user query.\\n\\nYou are provided with function signatures within <tools></tools> XML tags:\\n<tools>\" }}\n",
      "    {%- for tool in tools %}\n",
      "        {{- \"\\n\" }}\n",
      "        {{- tool | tojson }}\n",
      "    {%- endfor %}\n",
      "    {{- \"\\n</tools>\\n\\nFor each function call, return a json object with function name and arguments within <tool_call></tool_call> XML tags:\\n<tool_call>\\n{\\\"name\\\": <function-name>, \\\"arguments\\\": <args-json-object>}\\n</tool_call><|im_end|>\\n\" }}\n",
      "{%- else %}\n",
      "    {%- if messages[0]['role'] == 'system' %}\n",
      "        {{- '<|im_start|>system\\n' + messages[0]['content'] + '<|im_end|>\\n' }}\n",
      "    {%- else %}\n",
      "        {{- '<|im_start|>system\\nYou are Qwen, created by Alibaba Cloud. You are a helpful assistant.<|im_end|>\\n' }}\n",
      "    {%- endif %}\n",
      "{%- endif %}\n",
      "{%- for message in messages %}\n",
      "    {%- if (message.role == \"user\") or (message.role == \"system\" and not loop.first) or (message.role == \"assistant\" and not message.tool_calls) %}\n",
      "        {{- '<|im_start|>' + message.role + '\\n' + message.content + '<|im_end|>' + '\\n' }}\n",
      "    {%- elif message.role == \"assistant\" %}\n",
      "        {{- '<|im_start|>' + message.role }}\n",
      "        {%- if message.content %}\n",
      "            {{- '\\n' + message.content }}\n",
      "        {%- endif %}\n",
      "        {%- for tool_call in message.tool_calls %}\n",
      "            {%- if tool_call.function is defined %}\n",
      "                {%- set tool_call = tool_call.function %}\n",
      "            {%- endif %}\n",
      "            {{- '\\n<tool_call>\\n{\"name\": \"' }}\n",
      "            {{- tool_call.name }}\n",
      "            {{- '\", \"arguments\": ' }}\n",
      "            {{- tool_call.arguments | tojson }}\n",
      "            {{- '}\\n</tool_call>' }}\n",
      "        {%- endfor %}\n",
      "        {{- '<|im_end|>\\n' }}\n",
      "    {%- elif message.role == \"tool\" %}\n",
      "        {%- if (loop.index0 == 0) or (messages[loop.index0 - 1].role != \"tool\") %}\n",
      "            {{- '<|im_start|>user' }}\n",
      "        {%- endif %}\n",
      "        {{- '\\n<tool_response>\\n' }}\n",
      "        {{- message.content }}\n",
      "        {{- '\\n</tool_response>' }}\n",
      "        {%- if loop.last or (messages[loop.index0 + 1].role != \"tool\") %}\n",
      "            {{- '<|im_end|>\\n' }}\n",
      "        {%- endif %}\n",
      "    {%- endif %}\n",
      "{%- endfor %}\n",
      "{%- if add_generation_prompt %}\n",
      "    {{- '<|im_start|>assistant\\n' }}\n",
      "{%- endif %}\n",
      "\n",
      "INFO:gguf.gguf_writer:Writing the following files:\n",
      "INFO:gguf.gguf_writer:finetuned-lora.gguf: n_tensors = 290, total_size = 525.1M\n",
      "\n",
      "Writing:   0%|          | 0.00/525M [00:00<?, ?byte/s]\n",
      "Writing:  28%|██▊       | 145M/525M [00:03<00:09, 39.6Mbyte/s]\n",
      "Writing:  28%|██▊       | 149M/525M [00:03<00:09, 39.8Mbyte/s]\n",
      "Writing:  30%|███       | 159M/525M [00:03<00:09, 40.7Mbyte/s]\n",
      "Writing:  31%|███▏      | 165M/525M [00:04<00:08, 41.8Mbyte/s]\n",
      "Writing:  33%|███▎      | 174M/525M [00:04<00:08, 42.7Mbyte/s]\n",
      "Writing:  34%|███▍      | 181M/525M [00:04<00:07, 44.0Mbyte/s]\n",
      "Writing:  36%|███▌      | 190M/525M [00:04<00:07, 43.7Mbyte/s]\n",
      "Writing:  37%|███▋      | 197M/525M [00:04<00:07, 44.4Mbyte/s]\n",
      "Writing:  39%|███▉      | 206M/525M [00:04<00:07, 45.1Mbyte/s]\n",
      "Writing:  41%|████      | 213M/525M [00:05<00:06, 46.5Mbyte/s]\n",
      "Writing:  42%|████▏     | 222M/525M [00:05<00:06, 47.0Mbyte/s]\n",
      "Writing:  44%|████▎     | 229M/525M [00:05<00:06, 48.6Mbyte/s]\n",
      "Writing:  45%|████▌     | 238M/525M [00:05<00:05, 48.1Mbyte/s]\n",
      "Writing:  47%|████▋     | 244M/525M [00:05<00:05, 48.7Mbyte/s]\n",
      "Writing:  48%|████▊     | 254M/525M [00:05<00:05, 48.3Mbyte/s]\n",
      "Writing:  50%|████▉     | 260M/525M [00:06<00:05, 49.4Mbyte/s]\n",
      "Writing:  51%|█████▏    | 270M/525M [00:06<00:05, 48.6Mbyte/s]\n",
      "Writing:  53%|█████▎    | 276M/525M [00:06<00:05, 47.9Mbyte/s]\n",
      "Writing:  54%|█████▍    | 285M/525M [00:06<00:05, 45.4Mbyte/s]\n",
      "Writing:  56%|█████▌    | 292M/525M [00:06<00:05, 46.4Mbyte/s]\n",
      "Writing:  57%|█████▋    | 301M/525M [00:06<00:04, 45.8Mbyte/s]\n",
      "Writing:  59%|█████▊    | 308M/525M [00:07<00:04, 47.7Mbyte/s]\n",
      "Writing:  60%|██████    | 317M/525M [00:07<00:04, 47.0Mbyte/s]\n",
      "Writing:  62%|██████▏   | 324M/525M [00:07<00:04, 48.4Mbyte/s]\n",
      "Writing:  63%|██████▎   | 333M/525M [00:07<00:04, 48.0Mbyte/s]\n",
      "Writing:  65%|██████▍   | 340M/525M [00:07<00:03, 49.2Mbyte/s]\n",
      "Writing:  66%|██████▋   | 349M/525M [00:07<00:03, 48.0Mbyte/s]\n",
      "Writing:  68%|██████▊   | 355M/525M [00:08<00:03, 48.9Mbyte/s]\n",
      "Writing:  69%|██████▉   | 365M/525M [00:08<00:03, 48.7Mbyte/s]\n",
      "Writing:  71%|███████   | 371M/525M [00:08<00:03, 49.7Mbyte/s]\n",
      "Writing:  72%|███████▏  | 380M/525M [00:08<00:03, 47.8Mbyte/s]\n",
      "Writing:  74%|███████▎  | 387M/525M [00:08<00:02, 49.2Mbyte/s]\n",
      "Writing:  75%|███████▌  | 396M/525M [00:08<00:02, 49.3Mbyte/s]\n",
      "Writing:  77%|███████▋  | 403M/525M [00:08<00:02, 50.7Mbyte/s]\n",
      "Writing:  78%|███████▊  | 412M/525M [00:09<00:02, 49.6Mbyte/s]\n",
      "Writing:  80%|███████▉  | 419M/525M [00:09<00:02, 50.4Mbyte/s]\n",
      "Writing:  82%|████████▏ | 428M/525M [00:09<00:01, 49.5Mbyte/s]\n",
      "Writing:  83%|████████▎ | 435M/525M [00:09<00:01, 50.9Mbyte/s]\n",
      "Writing:  85%|████████▍ | 444M/525M [00:09<00:01, 49.9Mbyte/s]\n",
      "Writing:  86%|████████▌ | 450M/525M [00:09<00:01, 48.7Mbyte/s]\n",
      "Writing:  88%|████████▊ | 460M/525M [00:10<00:01, 48.2Mbyte/s]\n",
      "Writing:  89%|████████▉ | 466M/525M [00:10<00:01, 50.1Mbyte/s]\n",
      "Writing:  91%|█████████ | 476M/525M [00:10<00:01, 48.9Mbyte/s]\n",
      "Writing:  92%|█████████▏| 482M/525M [00:10<00:00, 50.1Mbyte/s]\n",
      "Writing:  94%|█████████▎| 491M/525M [00:10<00:00, 48.8Mbyte/s]\n",
      "Writing:  95%|█████████▍| 498M/525M [00:10<00:00, 50.3Mbyte/s]\n",
      "Writing:  97%|█████████▋| 507M/525M [00:11<00:00, 49.9Mbyte/s]\n",
      "Writing:  98%|█████████▊| 514M/525M [00:11<00:00, 50.3Mbyte/s]\n",
      "Writing: 100%|█████████▉| 523M/525M [00:11<00:00, 49.2Mbyte/s]\n",
      "Writing: 100%|██████████| 525M/525M [00:11<00:00, 45.6Mbyte/s]\n",
      "INFO:hf-to-gguf:Model successfully exported to finetuned-lora.gguf\n"
     ]
    }
   ],
   "source": [
    "!python ./llama.cpp/convert_hf_to_gguf.py ./qwen_choreo_merged --outfile finetuned-lora.gguf --outtype q8_0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac30138",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Convert to GGUF using huggingface-hub CLI\n",
    "print(\"\\nConverting model to GGUF format...\")\n",
    "!huggingface-hub-gguf convert {HF_OUTPUT_REPO} --outdir ./gguf_output --quantization-method q4_k_m\n",
    "\n",
    "print(\"\\nGGUF conversion complete! Files saved in: ./gguf_output\")\n",
    "\n",
    "print(\"\\nCreating Ollama modelfile...\")\n",
    "# Create an Ollama modelfile for easy import\n",
    "modelfile_content = \"\"\"\n",
    "FROM ./gguf_output/model-q4_k_m.gguf\n",
    "PARAMETER temperature 0.7\n",
    "PARAMETER top_p 0.9\n",
    "PARAMETER stop \"<|im_end|>\"\n",
    "PARAMETER stop \"<|im_start|>\"\n",
    "SYSTEM \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d54a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Write modelfile to disk\n",
    "with open(\"./qwen_choreo.modelfile\", \"w\") as f:\n",
    "    f.write(modelfile_content)\n",
    "\n",
    "print(\"Modelfile created at: ./qwen_choreo.modelfile\")\n",
    "print(\"\\nTo import the model into Ollama, run:\")\n",
    "print(\"ollama create qwen-choreo -f ./qwen_choreo.modelfile\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-slm-fine-tune",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
