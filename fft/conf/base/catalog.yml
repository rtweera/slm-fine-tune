# Here you can define all your datasets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://docs.kedro.org/en/stable/data/data_catalog.html

sentiments:
  type: fft.monkey_patch.PatchedHFDataset
  dataset_name: mteb/tweet_sentiment_extraction

raw_sentiments:
  type: pandas.ParquetDataset
  filepath: data/01_raw/raw_dataframe.pq

intermediate_sentiments:
  type: pandas.ParquetDataset
  filepath: data/02_intermediate/intermediate.pq

train_sentiments:
  type: pandas.ParquetDataset
  filepath: data/03_primary/train.pq

validation_sentiments:
  type: pandas.ParquetDataset
  filepath: data/03_primary/validation.pq

test_sentiments:
  type: pandas.ParquetDataset
  filepath: data/03_primary/test.pq

# train_y_sentiments:
#   type: pandas.ParquetDataset
#   filepath: data/03_primary/trainy.pq

# validation_y_sentiments:
#   type: pandas.ParquetDataset
#   filepath: data/03_primary/validationy.pq

# test_y_sentiments:
#   type: pandas.ParquetDataset
#   filepath: data/03_primary/testy.pq

tokenizer:
  type: fft.datasets.hf_model.HuggingFaceTokenizer
  model_name: Qwen/Qwen3-0.6B
  credentials: huggingface

tokenized_sentiments_readable_train:
  type: pandas.CSVDataset
  filepath: data/04_feature/tokenized_train.csv

tokenized_sentiments_train:
  type: fft.datasets.tokenized_dataset.HFDiskDataset
  filepath: data/04_feature/tokenized_train.pt

tokenized_sentiments_readable_validation:
  type: pandas.CSVDataset
  filepath: data/04_feature/tokenized_validation.csv

tokenized_sentiments_validation:
  type: fft.datasets.tokenized_dataset.HFDiskDataset
  filepath: data/04_feature/tokenized_validation.pt

tokenized_sentiments_readable_test:
  type: pandas.CSVDataset
  filepath: data/04_feature/tokenized_test.csv

tokenized_sentiments_test:
  type: fft.datasets.tokenized_dataset.HFDiskDataset
  filepath: data/04_feature/tokenized_test.pt

model:
  type: fft.datasets.hf_model.HuggingFaceCausalModel
  model_name: Qwen/Qwen3-0.6B
  credentials: huggingface