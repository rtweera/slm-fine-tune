# Here you can define all your datasets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://docs.kedro.org/en/stable/data/data_catalog.html

sentiments:
  type: fft.monkey_patch.PatchedHFDataset
  dataset_name: mteb/tweet_sentiment_extraction

raw_sentiments:
  type: pandas.ParquetDataset
  filepath: data/01_raw/raw_dataframe.pq

intermediate_sentiments:
  type: pandas.ParquetDataset
  filepath: data/02_intermediate/intermediate.pq

train_X_sentiments:
  type: pandas.ParquetDataset
  filepath: data/03_primary/trainX.pq

validation_X_sentiments:
  type: pandas.ParquetDataset
  filepath: data/03_primary/validationX.pq

test_X_sentiments:
  type: pandas.ParquetDataset
  filepath: data/03_primary/testX.pq

train_y_sentiments:
  type: pandas.ParquetDataset
  filepath: data/03_primary/trainy.pq

validation_y_sentiments:
  type: pandas.ParquetDataset
  filepath: data/03_primary/validationy.pq

test_y_sentiments:
  type: pandas.ParquetDataset
  filepath: data/03_primary/testy.pq

tokenizer:
  type: fft.datasets.hf_model.HuggingFaceTokenizer
  model_name: Qwen/Qwen3-0.6B

tokenized_sentiments_readable_train_X:
  type: pandas.CSVDataset
  filepath: data/05_model_input/tokenized_train_X.csv

tokenized_sentiments_train_X:
  type: fft.datasets.tokenized_dataset.TorchTokenizedDataset
  filepath: data/05_model_input/tokenized_train_X.pt

tokenized_sentiments_readable_validation_X:
  type: pandas.CSVDataset
  filepath: data/05_model_input/tokenized_validation_X.csv

tokenized_sentiments_validation_X:
  type: fft.datasets.tokenized_dataset.TorchTokenizedDataset
  filepath: data/05_model_input/tokenized_validation_X.pt

tokenized_sentiments_readable_test_X:
  type: pandas.CSVDataset
  filepath: data/05_model_input/tokenized_test_X.csv

tokenized_sentiments_test_X:
  type: fft.datasets.tokenized_dataset.TorchTokenizedDataset
  filepath: data/05_model_input/tokenized_test_X.pt
